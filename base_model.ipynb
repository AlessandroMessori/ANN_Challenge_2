{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport seaborn as sns\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nplt.rc('font', size=16)\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\nwarnings.filterwarnings('ignore')\ntf.get_logger().setLevel('ERROR')\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-15T16:33:59.745484Z","iopub.execute_input":"2021-12-15T16:33:59.745805Z","iopub.status.idle":"2021-12-15T16:34:07.059639Z","shell.execute_reply.started":"2021-12-15T16:33:59.745774Z","shell.execute_reply":"2021-12-15T16:34:07.058578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\nbatch_size = 64\nepochs = 200\nwindow = 200\nstride = 10\ntarget_labels = df.columns\ntelescope = 1\n\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:37:13.087194Z","iopub.execute_input":"2021-12-15T16:37:13.087792Z","iopub.status.idle":"2021-12-15T16:37:13.096761Z","shell.execute_reply.started":"2021-12-15T16:37:13.087742Z","shell.execute_reply":"2021-12-15T16:37:13.096099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/ann-challenge-2/Training.csv\")\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:34:16.518068Z","iopub.execute_input":"2021-12-15T16:34:16.518393Z","iopub.status.idle":"2021-12-15T16:34:16.743808Z","shell.execute_reply.started":"2021-12-15T16:34:16.518359Z","shell.execute_reply":"2021-12-15T16:34:16.742379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_size = int(df.shape[0] / 4)\nX_train_raw = df.iloc[:-test_size]\n# y_train_raw = y.iloc[:-test_size]\nX_test_raw = df.iloc[-test_size:]\n# y_test_raw = y.iloc[-test_size:]\nprint(X_train_raw.shape, X_test_raw.shape)\n\n# Normalize both features and labels\nX_min = X_train_raw.min()\nX_max = X_train_raw.max()\n\nX_train_raw = (X_train_raw-X_min)/(X_max-X_min)\nX_test_raw = (X_test_raw-X_min)/(X_max-X_min)\n\nplt.figure(figsize=(17,5))\nplt.plot(X_train_raw.Sponginess, label='Train (sponginess)')\nplt.plot(X_test_raw.Sponginess, label='Test (sponginess)')\nplt.title('Train-Test Split')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:34:18.6747Z","iopub.execute_input":"2021-12-15T16:34:18.674994Z","iopub.status.idle":"2021-12-15T16:34:19.057228Z","shell.execute_reply.started":"2021-12-15T16:34:18.674965Z","shell.execute_reply":"2021-12-15T16:34:19.056359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_sequences(df, target_labels, window=200, stride=20, telescope=100):\n    # Sanity check to avoid runtime errors\n    assert window % stride == 0\n    dataset = []\n    labels = []\n    temp_df = df.copy().values\n    temp_label = df[target_labels].copy().values\n    padding_len = len(df)%window\n\n    if(padding_len != 0):\n        # Compute padding length\n        padding_len = window - len(df)%window\n        padding = np.zeros((padding_len,temp_df.shape[1]), dtype='float64')\n        temp_df = np.concatenate((padding,df))\n        padding = np.zeros((padding_len,temp_label.shape[1]), dtype='float64')\n        temp_label = np.concatenate((padding,temp_label))\n        assert len(temp_df) % window == 0\n\n    for idx in np.arange(0,len(temp_df)-window-telescope,stride):\n        dataset.append(temp_df[idx:idx+window])\n        labels.append(temp_label[idx+window:idx+window+telescope])\n\n    dataset = np.array(dataset)\n    labels = np.array(labels)\n    return dataset, labels","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:34:21.820421Z","iopub.execute_input":"2021-12-15T16:34:21.821566Z","iopub.status.idle":"2021-12-15T16:34:21.83622Z","shell.execute_reply.started":"2021-12-15T16:34:21.821495Z","shell.execute_reply":"2021-12-15T16:34:21.835169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_CONV_LSTM_model(input_shape, output_shape):\n    # Build the neural network layer by layer\n    input_layer = tfkl.Input(shape=input_shape, name='Input')\n\n    convlstm = tfkl.Bidirectional(tfkl.LSTM(64, return_sequences=True))(input_layer)\n    convlstm = tfkl.Conv1D(128, 3, padding='same', activation='relu')(convlstm)\n    convlstm = tfkl.MaxPool1D()(convlstm)\n    convlstm = tfkl.Bidirectional(tfkl.LSTM(128, return_sequences=True))(convlstm)\n    convlstm = tfkl.Conv1D(256, 3, padding='same', activation='relu')(convlstm)\n    convlstm = tfkl.GlobalAveragePooling1D()(convlstm)\n    convlstm = tfkl.Dropout(.5)(convlstm)\n\n    # In order to predict the next values for more than one channel,\n    # we can use a Dense layer with a number given by telescope*num_channels,\n    # followed by a Reshape layer to obtain a tensor of dimension \n    # [None, telescope, num_channels]\n    dense = tfkl.Dense(output_shape[-1]*output_shape[-2], activation='relu')(convlstm)\n    output_layer = tfkl.Reshape((output_shape[-2],output_shape[-1]))(dense)\n    output_layer = tfkl.Conv1D(output_shape[-1], 1, padding='same')(output_layer)\n\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n\n    # Compile the model\n    model.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(), metrics=['mae'])\n\n    # Return the model\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:34:39.936548Z","iopub.execute_input":"2021-12-15T16:34:39.9376Z","iopub.status.idle":"2021-12-15T16:34:39.949523Z","shell.execute_reply.started":"2021-12-15T16:34:39.937537Z","shell.execute_reply":"2021-12-15T16:34:39.948752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = build_sequences(X_train_raw, target_labels, window, stride, telescope)\nX_test, y_test = build_sequences(X_test_raw, target_labels, window, stride, telescope)\nX_train.shape, y_train.shape, X_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:37:37.451095Z","iopub.execute_input":"2021-12-15T16:37:37.451424Z","iopub.status.idle":"2021-12-15T16:37:37.56139Z","shell.execute_reply.started":"2021-12-15T16:37:37.451385Z","shell.execute_reply":"2021-12-15T16:37:37.560258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = X_train.shape[1:]\noutput_shape = y_train.shape[1:]\nbatch_size = 64\nepochs = 200","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:37:38.84894Z","iopub.execute_input":"2021-12-15T16:37:38.849253Z","iopub.status.idle":"2021-12-15T16:37:38.854611Z","shell.execute_reply.started":"2021-12-15T16:37:38.849222Z","shell.execute_reply":"2021-12-15T16:37:38.853651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_CONV_LSTM_model(input_shape, output_shape)\nmodel.summary()\ntfk.utils.plot_model(model, expand_nested=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:37:41.344025Z","iopub.execute_input":"2021-12-15T16:37:41.344504Z","iopub.status.idle":"2021-12-15T16:37:42.854177Z","shell.execute_reply.started":"2021-12-15T16:37:41.34446Z","shell.execute_reply":"2021-12-15T16:37:42.853132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    x = X_train,\n    y = y_train,\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_split=.1,\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.5, min_lr=1e-5)\n    ]\n).history","metadata":{"execution":{"iopub.status.busy":"2021-12-15T16:37:48.142797Z","iopub.execute_input":"2021-12-15T16:37:48.143187Z","iopub.status.idle":"2021-12-15T17:02:36.967316Z","shell.execute_reply.started":"2021-12-15T16:37:48.143148Z","shell.execute_reply":"2021-12-15T17:02:36.966058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('AuroregressiveForecasting')","metadata":{"execution":{"iopub.status.busy":"2021-12-15T17:02:40.681185Z","iopub.execute_input":"2021-12-15T17:02:40.681728Z","iopub.status.idle":"2021-12-15T17:03:06.481404Z","shell.execute_reply.started":"2021-12-15T17:02:40.681692Z","shell.execute_reply":"2021-12-15T17:03:06.480303Z"},"trusted":true},"execution_count":null,"outputs":[]}]}